{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needle(s) in a Haystack Test\n",
    "\n",
    "How many 'needles' can GPT4o extract from a large amount of context? For reference there are about 21,600 tokens in the Microsoft Build Document.\n",
    "\n",
    "Let's have GPT4o generate a structured table based on the announcments from Microsoft Build 2024!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries üßë‚Äçüíª\n",
    "\n",
    "We are brining in a few libraries here, most of them are LangChain Libraries:\n",
    "\n",
    "1. AzureAIDocumentIntelligenceLoader again to load and convert the PDF to Markdown\n",
    "\n",
    "2. AzureChatOpenAI to send and receive API requests from GPT4o\n",
    "\n",
    "3. ChatPromptTemplate so we can build a prompt to ask GPT4o to structure data for us\n",
    "\n",
    "4. StrOutputParser to ensure the output from the LLM is in string format. This is important since we are going to leverage Pandas to query the data once we have it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n",
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Microsoft Build Document üìÑ\n",
    "\n",
    "Load the Book of News Doucument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = AzureAIDocumentIntelligenceLoader(file_path=\"C:\\\\Users\\\\conne\\\\development\\\\repos\\\\chunking_for_rag\\\\Book_Of_News.pdf\", api_key=os.environ.get('DOCUMENT_INTELLIGENCE_KEY'), api_endpoint=os.environ.get('DOCUMENT_INTELLIGENCE_ENDPOINT'), api_model=\"prebuilt-layout\")\n",
    "book_of_build = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in GPT4o ü§ñ\n",
    "\n",
    "Bring in GPT4o with the extra large context window of 96,000 words. This is the LLM we are going to feed 21,600 words of the Book of News document to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt4o\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=\"2024-02-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an LLM Call to Make Untructured Data Structured üìû\n",
    "\n",
    "Let's see how many 'needles' GPT4o can extract from 21,600 words and effectivley structure it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an assistant that will summarize all of the Azure AI and Data Services announcements in the below context. Make sure to put the data into the following table. Make sure to only respond with the table and nothing else.\n",
    "\n",
    "| Service      | Announcement |\n",
    "|--------------|--------------|\n",
    "|              |              |             \n",
    "\n",
    "Context:\n",
    "{docs_string}\n",
    "\"\"\")\n",
    "\n",
    "docs_string = \"\"\n",
    "for page in book_of_build:\n",
    "    docs_string += page.page_content\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "table = chain.invoke({\"docs_string\": book_of_build})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print LLM Generated Table ü§ñ\n",
    "\n",
    "Let's have a look at the table GPT4o generated for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minor Data Cleaning üßº\n",
    "\n",
    "Let's get the LLM generated table into a format we can query in Pandas üêº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "rows = [row.strip().split('|') for row in table.strip().split('\\n')[2:]]\n",
    "data_list = [[value.strip() for value in row[1:-1]] for row in rows]\n",
    "df = pd.DataFrame(data_list, columns=[\"Service\", \"Announcement\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query using Pandas üêº\n",
    "\n",
    "Write a few Pandas Query to filter the data that the LLM generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ai_df = df[df['Service'] == 'Azure AI Services']\n",
    "print(azure_ai_df)\n",
    "\n",
    "azure_ai_df = df[df['Service'] == 'Developer Tools & DevOps']\n",
    "print(azure_ai_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
