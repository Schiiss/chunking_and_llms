{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n",
    "import os\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = AzureAIDocumentIntelligenceLoader(api_endpoint=os.environ.get('DOCUMENT_INTELLIGENCE_ENDPOINT'), api_key=os.environ.get('DOCUMENT_INTELLIGENCE_KEY'), file_path='C:\\\\Users\\\\conne\\\\development\\\\repos\\\\converting_unstructured_data_to_structured_data_using_gpt4o\\\\Book_Of_News.pdf')\n",
    "docs = loader.load()\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "docs_string = docs[0].page_content\n",
    "splits = text_splitter.split_text(docs_string)\n",
    "\n",
    "print(\"Length of splits: \" + str(len(splits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Document Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in GPT4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt4o\",\n",
    "    temperature=0,\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=\"2024-02-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an LLM Call to make untructured data structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an assistant that will summarize all of the Generative AI announcements in the below context. Make sure to put the data into the following table. Make sure to only respond with the table and nothing else.\n",
    "\n",
    "| Service | Announcement | \n",
    "|--------------|--------------|\n",
    "|              |              |\n",
    "\n",
    "Context:\n",
    "{docs_string}\n",
    "\"\"\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "table = chain.invoke({\"docs_string\": splits})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query using Pandas üêº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Remove leading and trailing whitespaces and split the table into rows\n",
    "rows = [row.strip().split('|') for row in table.strip().split('\\n')[2:]]\n",
    "\n",
    "# Extract data from each row\n",
    "data_list = [[value.strip() for value in row[1:-1]] for row in rows]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data_list, columns=[\"Service\", \"Announcement\"])\n",
    "\n",
    "# Assuming you've already created the DataFrame df as shown in the previous code snippet\n",
    "\n",
    "# Query where Service equals 'Azure Data'\n",
    "azure_data_df = df[df['Service'] == 'Azure Data']\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "print(azure_data_df)\n",
    "\n",
    "azure_ai_df = df[df['Service'] == 'Azure AI Services']\n",
    "\n",
    "print(azure_ai_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
